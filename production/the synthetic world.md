# The Synthetic Worlds

## Introduction

Le monde que nous habitons n'a peut-être jamais existé en tant que "donnée" brute, mais toujours et plutôt en tant que construction. Ils est fabriqués par des techniques, des récits, des représentations qui filtrent et reconfigurent nos perceptions. Comme le rappelle Stéphane Vial, "[la technique conditionne la manière dont le réel ou l’être nous apparaît](../documentation/observations/le%20monde%20est%20une%20perception%20technique.md)" (Vial, 2017, p76) : elle agit comme un appareillage perceptif qui compose notre rapport au monde. Ce réel est donc un ensemble "[multiples (de) couches interconnectées](../documentation/observations/les%20multiples%20couches%20interconnectées%20dont%20dépend%20le%20calcul%20à%20l'échelle%20planétaire.md)" (Wikipedia, 2025), somatiques, symboliques et techniques, qui participe à la fabrication - et parfois peut-être à la destruction - de "[l'habitabilité du monde](../documentation/observations/habitabilité%20du%20monde.md)" (Gauthier & cie, 2014).

Ces multiples couches produise ce que je propose de nommer "les mondes synthétiques". Des mondes modelés par la logique du calcul, par la prédiction, par l’anthropomorphisation des machines et par la délégation progressives de nos facultés d'être-au-monde. Monde "dataset", monde "vernis", monde "délégué" et monde "résistant" : ces mondes coexistent, se superposent, parfois s’affrontent. Ensemble, ils dessinent une mutation profonde de notre rapport au réel et reconfigure silencieusement la place - et surtout le role - que nous y tenons. 
## Un monde "dataset"

L'émergence de la cybernétique semble être l’un des glissements majeurs du XXᵉ siècle. En  étudiant "[la manière dont les systèmes de communication pouvaient servir à des fins de contrôle](../documentation/observations/cybernétique%20et%20contrôle.md)" (Turner, 2014), Norbert Wiener définit la cybernétique comme "[un champ dédié à « l'étude des messages en tant que moyens de contrôle sur les machines et la société », les machines incluant vraisemblablement, par analogie tout au moins, les organismes biologiques](../documentation/observations/définition%20de%20la%20cybernétique.md)" (Turner, 2006, p.62). Il semblerait qu’elle ait ainsi contribué à la transformation progressive du monde en système d’information, dans lequel territoires, corps, gestes et comportements deviennent des données calculables, compréhensibles et traitables par des machines.

Cette transformation semble s’inscrire dans une quête de "singularité technologique" : la machine "comprend" désormais l’environnement, le contexte, l’objectif, et est capable d’agir seule. Une idéologie proche de celle du transhumanisme qui  "[s'appuie sur un scénario tout tracé, selon lequel l'humanité, dépassée par les performances de ses machines, sera bientôt à la merci d'une "superintelligence" prenant le contrôle de son destin](../documentation/observations/idéologie%20transhumaniste.md)" (Alombert, 2025, p.12). En somme, [une machine de toutes les machines](../documentation/observations/la%20machine%20de%20toutes%20les%20machines.md) (Simondon, 1989, p.11).

Cette datafication intensive du monde engendre des modification considérables de nos environnement, en les transformant selon des règles "primo-techniques. Des paysages entiers sont balisés, quadrillés, afin de rendre le vivant compatible avec des logiques de prédiction algorithmique. Ils deviennent des surfaces lisibles pour des capteurs et des modèles prédictifs. 

James Bridle cite par exemple le cas d’une région en Grèce, où des zones naturelles sont désormais balisées par et pour des dispositif technique, avec l'objectif d'y extraire des métaux rares : "[autant de jalons posés par une force venue d'ailleurs, résultat des opérations d'une intelligence artificielle optimisée pour extraire les ressources nécessaires afin de soutenir la sacro-sainte croissance économique, quel qu'en soit le coût.](../documentation/observations/extraction%20en%20épire.md)" (p.21).

Ainsi, le monde "dataset" se configure pour le bon fonctionnement des machines, au détriment de celui des êtres vivant qui l’habitent. Il s’instrumentalise, et transforme l’expérience "d'être au monde" en variable à ajuster, interpréter ou contrôler . Un monde pensé pour être calculé d'abord, et non plus vécu.
## Un monde "vernis"

Pour être comprise, utilisable et paraitre, d’une certaine manière, plus "naturelle", la machine - quelle que soit sa forme - se voit appliquée d’un vernis anthropomorphique. Cette couche d’humanité simulée se dissimule derrière des principes d'accessibilité, renforçant l'idée "[qu'à l'avenir, des agents d'IA capables de simuler et de répondre avec précision aux émotions humaines seront essentiels pour élargir l'adoption de l'intelligence artificielle](../documentation/observations/simuler%20les%20émotions%20humaine%20pour%20augmenter%20l'adoption.md)" (Origami, 2024).

Cette façon de penser l'interfaçage homme-machine a pour effet de réduire la complexité de nos dispositifs techniques, rendant leurs usages plus faciles. D'un autre côté, cette couche de "vernis" anthropomorphique rend difficile la lecture critique de ce qui se joue dans les usages, qu’il s’agisse de retombées écologiques, sociales, psychiques, symboliques voir même civilisationnelles.

Autrement dit, le fait que "[les machines computationnelles n'automatisent plus seulement les savoir-faire, mais aussi les savoir-penser](../documentation/observations/exploitation%20des%20ressources%20symboliques%20et%20culturelles.md)" (Alombert, 2025, p.29) ou que "[les industries numériques n'exploitent plus seulement les ressources naturelles ou matérielles mais aussi les ressources symboliques et culturelles"](../documentation/observations/exploitation%20des%20ressources%20symboliques%20et%20culturelles.md) (ibid) demeure souvent imperceptible dans nos pratiques numériques quotidiennes. 

L’émergence du Vibe Coding semble renforcer cette tendance, déplaçant le processus même de fabrication des dispositifs techniques vers le registre d’une conversation naturelle : on "parle" désormais à la machine plutôt que de la programmer. "[Communiquer remplace la nécessité de connaître le manuel](../documentation/observations/la%20communication%20remplace%20le%20manuel.md)"(Vercel, 2025) ; on ne code plus des instructions, on formule des intentions. "[L’anglais est en train de devenir le langage de programmation le plus puissant au monde - et nous assistons à cela aux premières loges](../documentation/observations/l'anglais%20comme%20langage%20de%20programmation.md)" (ibid).

Ce déplacement démocratise l’accès à un dimaine longtemps réservé à l'ingénierie logicielle, si bien qu’aujourd’hui, sans vibe coding, "[le projet ne naît pas, l’idée ne se communique pas, l’application ne sort jamais](../documentation/references/vibe%20coding%20and%20elite%20engineering.md)", explique Guillermo Rauch, CEO de Vercel. 

Derrière la transformation de ces intentions en code, se cachent une série de couches de calcul inaccessibles. C'est ce que Bratton décrit comme une "[mégastructure accidentelle](../documentation/observations/mégastructure%20accidentelle.md)" (Wikipedia, 2025), une architecture computationnelle à l’échelle planétaire opérant en dessous du seuil de perception humaine.

En retour, cette pratique produit une nouvelle forme d’opacité. Le confort dans les usages comme dans les processus de conception devient alors une forme d’anesthésie critique. John Maeda décrit ce phénomène comme une « illusion de transparence », où la simplicité de surface masque une complexité systémique inatteignable: "[les pixels d’un écran ne nous apprennent rien sur la machine computationnelle à laquelle ils sont connectés.](../documentation/observations/illusion%20de%20transparence.md)" (Maeda, 2025, p.12). 

Ce décalage entre la simplicité de l’expérience et la densité technique du système produit une perte de maîtrise cognitive : nous n’avons plus les outils pour penser les machines qui nous gouvernent. "[Au contraire, les normes techniques (…) sont dissimulées derrière des interfaces ergonomiques, qui permettent un usage immédiat et intuitif, mais rarement réflexif](../documentation/observations/usage%20ergonomique%20et%20non%20réflexif.md)" (Alombert, 2023)

Cette transparence trompeuse maintient l’illusion d’un monde sensible, alors même que l’humain semble devenir de plus en plus secondaire dans sa propre architecture technique. Non seulement nous perdons l’accès à ce qui se joue, mais nous déléguons à la machine aussi, peu à peu, nos propres facultés - au risque, peut-être, de les voir s’atrophier.
## Un monde "délégué"

Le monde que nous habitons semble désormais fabriqué - et parfois pensé - par les machines que nous avons créées. Simondon rappelait déjà que "[la machine prend la place de l’homme parce que l’homme accomplissait une fonction de machine](../documentation/observations/l'homme%20porteur%20d'outil.md)" (1958, p.15) et que, ce faisant, nous en venons à "[lui déléguer notre humanité](../documentation/observations/domination%20par%20la%20machine%20androïde.md)" (p.11). 

Si "[La machine est ce par quoi l'homme s'oppose à la mort de l'univers](../documentation/observations/la%20machine%20comme%20objet%20de%20lutte%20contre%20la%20mort.md)" (Simondon, 1958, p.15-16), n'est elle par d'abord une tentative effrénée de lutte contre notre propre mortalité ? Si "[se souvenir de la mort nous aide à mieux vivre dans cette vie](../documentation/observations/la%20mort%20nous%20rapproche%20de%20la%20vie.md)" (Bertolotti, 2023), que se passerait-il si nous devenions immortel ? Que se passera-t-il lorsque nous seront en mesure de "tout" controller ? Que nous restera-t-il ?

A moindre mesure, pendant nous travaillons à construction de "[la machine à penser, (...) la machine à vouloir, la machine à vivre](../documentation/observations/domination%20par%20la%20machine%20androïde.md)" (Simondon, 1958, p.11), se mettent en place de nouveau processus qui engendre "[non plus seulement l'automatisation des savoir-faire, mais aussi l'automatisation des savoir-penser](../documentation/observations/automatisation%20des%20savoir%20penser.md)" (Alombert, 2025, p.22).

Cette délégation traduit aussi la sacralisation de la technique : nous conférons à la machine une autorité morale, un pouvoir de décision. Nous laissons les algorithmes juger à notre place ce qu’il convient de faire ou de dire - par exemple, dans la rédaction d’un message, d’un mail, ou d'une déclaration d’amour.

Nous ne déléguons plus seulement nos calculs, mais nos choix, nos évaluations, nos jugements — et peut-être même, en un sens, nos émotions. Comme le rappelle Hubert Guillaud, "[les algorithmes sont des opinions encapsulés dans du code](../documentation/observations/les%20algorithmes%20sont%20des%20opinions%20encapsulés%20dans%20du%20code.md)" (Guillaud, 2023, p.31) : et ce sont désormais ces opinions qui orientent nos vies quotidiennes.

"[Les savoir-décider sont extériorisés dans les algorithmes de recommandation automatique, qui décident à notre place quel contenu consulter. Les savoir-traduire sont extériorisés dans les logiciels de traduction automatique, qui traduisent à notre place dans la langue exigée. Les savoir-écrire sont extéricicés dans les générateurs automatique de texte qui expriment, à notre place, nos idées.](../documentation/observations/extériorisation%20des%20savoirs.md)" (Alombert, 2025, p.23)

Ce faisant, en sollicitant un modèle de langage pour rédiger un texte, nous laissons la machine colorer nos propos, choisir l’enchaînement des mots, et nous nous privons de la part de ressenti liée à l’acte même d’écrire. Le faire-faire devient un faire-penser ou un faire-ressentir : le processus de création - et donc en un sens de ressentir - se déplace hors du corps humain.

Pourtant, la machine ne ressent pas : elle performe. L’efficacité devient son seul horizon moral. Comme le souligne Jacques Ellul, l’État moderne - tout comme la technique - est désormais régi par "[une même logique : l’efficacité, au nom d’un exercice de la rationalité](../documentation/observations/efficacité%20comme%20une%20norme.md)" (Larmagnac-Matheron, 2024), signe que cette valeur s’impose comme norme supérieure à toute considération humaine ou morale.

Et c’est certainement dans cette efficacité que réside le potentiel destructeur de la machine. Sur le monde, comme le démontre l'expérience de pensée de la logique sans fin du Paperclip Maximizer, où une IA détruit le monde pour accomplir son objectif de fabrication de trombone ([EGO, 2024](../documentation/references/l'horreur%20existentielle%20de%20l'usine%20à%20trombones.md)). Et sur les individus, avec la "[destruction progressive des facultés de penser, par une industrie numérique qui fait des énergies psychiques sa première source de profit économique](../documentation/observations/destruction%20progressive%20des%20facultés%20de%20penser.md)" (Alombert, 2023, p.14)

Ce glissement vers une morale de l’efficacité risque donc de produire un effet miroir : nous nous algomorphisons. Nous cherchons à nous transcender, à nous optimiser, à nous augmenter. L’humain devient modèle de performance et la machine, objet d’attachement et de dépendance du savoir-être-au-monde. Comme le montre Catalog for the Post-Human, nous entrons dans une ère où "[le succès dépend de notre capacité à rester mentalement aiguisés, continuellement quantifiés, et prêts à travailler selon les horaires irréguliers dictés par des entreprises pilotées par des algorithmes](../documentation/observations/le%20succès%20dépend%20de%20notre%20augmentation.md)" (Parsons & Charlesworth, 2021). La délégation devient alors un impératif : déléguer pour tenir, déléguer pour suivre, déléguer pour rester compétitif - quitte à céder nos propres facultés.
## Un monde "résistant"

Face à cette totalisation du calcul et de la délégation, certaines pratiques semblent réintroduire la possibilité d’autres futurs. La techno-désobéissance ou les mouvements open-source rouvrent des espaces de partage, d’expérimentation et de débat. Comme le rappelait Jacques Ellul, "[l’homme est placé devant un choix exclusif : utiliser la technique comme elle doit l’être selon les règles techniques, ou ne pas l’utiliser du tout](../documentation/observations/échapper%20à%20la%20technique.md)" (Larmagnac-Matheron, 2024).  Cette possibilité du refus demeure peut-être l’un des derniers gestes politiques face au système technicien. 

Cette éloge de la "non-puissance", qui se distingue de l'impuissance par le fait qu'elle demeure un choix : "[je peux et ne le ferai pas](../documentation/observations/eloge%20de%20la%20non-puissance.md)" (A PRECISER), invite à une réappropriation critique du monde technique, notamment par la lenteur, la friction, et la transparence. Il s'agit autrement dit - en un sens - de s'opposer à la quête de la performance et peut-être, en un sens, à accepter sa condition de "mortel", ou plus globalement d'existance finie dans un monde fini. 

Mais pour y arriver, encore faut-il avoir le choix, ou du moins, avoir conscience que l'on a le choix. Comment lutter contre l'absence du sentiment d'absence qu'engendre l'opacité de nos systèmes technique ? Est-il nécessaire de mettre en place "[un véritable contrôle démocratique des technologies](../documentation/observations/contrôle%20démocratique%20des%20technologies.md)" (Régnauld, I., & Benayoun, Y. 2024, p.179) ?

Comment redonner un pouvoir d’agir et de comprendre aux individus sans retomber dans la sur-simplification ? La théorie des capabilités d’Amartya Sen rappelle que la liberté n’est pas un état abstrait mais la possibilité concrète d’agir : La capabilité reflète la liberté de l’individu d’accéder à telle ou telle combinaison de modes de fonctionnement, autrement dit "[de choisir entre différentes conditions de vie](../documentation/observations/liberté%20de%20choix.md)" (Monnet, 2007). Autrement dit, il ne s’agit pas seulement d’offrir des options, mais de rendre réellement possibles les conditions d’un choix, d’un rapport actif au monde technique.

Le design fiction apparaît ici comme un outil de médiation intéressant : il permet de matérialiser des fragments de futurs, de les rapporter au présent et d’en faire des objets de discussion et de débat. Comme le résume Julian Bleecker, "[le design fiction est la pratique qui consiste à créer des prototypes tangibles et évocateurs issus de futurs possibles proches, afin d’explorer et de rendre visibles les conséquences des décisions que nous prenons](../documentation/observations/design%20fiction.md)" (Bleecker, n.d.). Il semble ainsi offrir un moyen pertinent pour aborder la dimension "poison" du pharmakon (==INTRODUIRE CONCEPT==) technique, sans exiger de maîtriser l’ensemble de ses mécanismes internes.

Ce faisant, les prototypes diégétiques donnent forme a des logiques a-priori invisibles, offrant une intelligibilité sensible à ce qui échappe au regard du quotidien. Ces approches et usages de la technologies s’opposent en un sens au solutionnisme technologique, en réintroduisant la pluralité des possibles et en réouvrant le débat public sur le devenir technologique. Ils rappellent ainsi que "[les technologies ne sont pas d'emblée des solutions: elles doivent faire l'objet d'interprétations, de réflexions, de délibérations et de décisions - elles doivent être adoptées socialement et politiquement](../documentation/observations/la%20technique%20n'est%20pas%20neutre.md)" (Alombert, 2025, p.42).

C'est peut-être ce qu'invite Jacque Ellul à faire lorsqu'il rappelle qu'on "[ne peut pas luter contre l’efficacité avec efficacité. On doit utiliser des choses qui ne sont pas efficaces, qui prennent leur temps](../documentation/observations/luter%20contre%20la%20technique.md)" (Devaux et cie., 2025). Il s'oppose en somme à l'idée de combattre la démesure technique par une surenchère technologique, là ou "[l’augmentation devient destruction et le remède poison](../documentation/observations/la%20mémoire%20artificielle%20rend%20l’oubli%20habituel.md)" (Alombert, 2023, p.43). Le design fiction, au contraire, propose de réintroduire le symbolique, le récit et la réflexivité comme antidotes à "[l’automatisation de la pensée](../documentation/observations/automatisation%20de%20la%20pensée.md)" (ibid, p.44).

On peut y lire une issue - fragile, mais possible. Si tout est délégué aux machines, il restera peut-être à l’humain la question du sens : qu’est-ce qu’être vivant, qu’est-ce que l'amour, qu’est-ce qu’éprouver ? Qu'est-ce qu'être humain ? L’automatisation totale pourrait paradoxalement nous ramener à ces interrogations fondamentales, et forcer un retour à l’émotion, au doute, à la réflexivité... pour autant que nous soyons encore capable de penser. 

C’est peut-être aussi ce qu’annonçait, avec une naïveté désarmante, le poème de Richard Brautigan :

> [Sous la haute surveillance de machines pleines d'amour et de grâce](../documentation/observations/sous%20la%20haute%20surveillance%20de%20machines%20pleines%20d'amour%20et%20de%20grâce.md) 
> 
> *Il me plaît à imaginer (et le plus tôt le mieux!) une prairie cybernétique ou mammifères et ordinateurs vivent ensemble une harmonie mutuellement programmée semblable à de l'eau pure effleurant un ciel sans nuage.*
> 
> *Il me plaît à imaginer (tout de suite, allons!) une forêt cybernétique semée d'électronique et de pins où les cerfs flânent en paix au-dessus d'ordinateurs pareils à des fleurs aux pétales filés.*
> 
> *Il me plaît à imaginer (il en sera ainsi!) une écologie cybernétique où nous sommes libres de tout travail réunis à la nature, mêlés aux mammifères nos frères et sœurs et sous la haute surveillance de machines pleines d'amour et de grâce.*

(Turner, 2006, p-94)

Les mondes synthétiques semblent ainsi réaliser le "vieux" rêve cybernétique : une réalité convertie en informations. Mais il reste à savoir si, dans ce paysage quadrillé par le calcul, nous pourrons encore entendre autre chose que le bruit des machines - un geste, un doute, un frémissement. C’est peut-être là que se joue notre avenir : dans la part de vivant qui échappe encore aux modèles ?

---
# The Synthetic Worlds 

## Intentions

- Met en scène la logique extractiviste de l’IA, qui puise dans les productions humaines plutôt qu’elle ne "génère" véritablement, et rappelle les coûts invisibles de cette extraction.
- Montre comment nous remodelons progressivement le monde pour l’adapter aux attentes des machines, afin qu’il devienne entièrement découpable, mesurable, indexable.
- Recompose la planète à partir de “Hello, World!”, ces premiers mots prononcés par un humain face à une machine : une manière de signifier que le monde lui-même devient un message adressé aux systèmes computationnels.
- Représente la fin ou l’aboutissement d’un cycle : celui de la numérisation du monde.
- Les doubles barres “//” inscrivent “synthetic” comme un commentaire de code, et rappellent subtilement les deux bâtons de la figure féminine de la carte originelle.
- La grille évoque l’uniformisation des formes de vie et de pensée sous l’effet du calcul, la rationalisation des savoir-faire, et la mise à plat des singularités culturelles.
- Le choix typographique renvoie au Whole Earth Catalog, symbole d’un imaginaire technologique à la fois utopique et pré-internet.
- L’usage de l’ASCII renvoie à l’histoire des mémoires artificielles, et plus largement à la traduction du monde en signes manipulables par les ordinateurs.
- L’ASCII évoque aussi la pauvreté expressive des systèmes techniques, - réduisant la complexité du monde à des symboles élémentaires (ici "hello world")
- La composition “monde + grille” rappelle les fantasmagories cybernétiques des années 1960-70, notamment les environnements immersifs du Pepsi Pavilion ou les visions “globales” de Fuller et du Whole Earth Catalog.
- Le vide autour du globe suggère la disparition du vivant dans un espace totalement calculé.
## Aperçu

![The Synthetic Worlds](assets/the%20synthetic%20worlds.png)

(Sera imprimée avec un Robot Axidraw)

---
# À placer dans mon texte ? 

[exploitation des ressources symboliques et culturelles](../documentation/observations/exploitation%20des%20ressources%20symboliques%20et%20culturelles.md)

Comme l’écrit De Smet, "[la conscience est une construction mentale que le cerveau construit comme sas entre deux chaos : celui de nos propre neurones d'une part et celui du monde d'autre part](../documentation/observations/la%20conscience%20comme%20sas%20entre%20deux%20chaos.md)" (De Smet, 2017). Notre perception du monde serait alors produite par un dispositif artificiel - un appareillage perceptif-somatique-symbolique aussi appelé « je ». 

Qu'il s'agisse de techno-mysticisme, notamment au travers d'expérience interactive qui "[ressemble quelque peu à une expérience psychédélique](../documentation/observations/expérience%20interactive%20psychédélique.md)" (Turner, 2014) , d'organisme cybernétiques, web, écriture, ...

Dans le jeu traditionnel du Tarot, la carte du Monde symbolise l’achèvement d’un cycle, et le commencement d'un autre; le passage d'un état de convergence à un état de divergence. 
Suzane Treister, au travers de son projet HEXGEN 2.0, qui "[explore simultanément diverses réponses philosophiques, littéraires et politiques aux progrès technologiques](../documentation/references/hexgen%202.0.md)" (Treister, 2009-2011).

Peut-être par peur du chaos qu'il représente, ne sommes-nous pas progressivement en train de déléguer notre capacité à le comprendre, l'interpréter et ainsi le fabriquer à une série d'artifice technique qui - depuis l'invention de l'écriture, semble augmenter notre potentialité de délégation à des artifices auxiliaire