# The Synthetic Worlds

## Introduction


Le monde est multi stack. https://en.wikipedia.org/wiki/The_stack_(philosophy)



Lien avec Vial : le virtuel est réel, c'est du potentiel. Et la simulation permet de rendre visible une réalité invisible, même si celle ci n'est pas réelle : anthropomorphisation. 

C’est peut-être là la condition de maintien d’une forme d’habitabilité du monde technique : un monde lissé, émotionnellement acceptable, dans lequel la froideur du calcul est recouverte d’un langage empathique. Or, la machine ne comprend pas, ne pense pas — elle calcule.

[exploitation des ressources symboliques et culturelles](../documentation/observations/exploitation%20des%20ressources%20symboliques%20et%20culturelles.md)

Le monde a-t-il jamais été autre chose qu'une construction ? Une réalité artificielle faite de représentations plurielle ? Une strate de couches perceptives et symboliques qui fabrique à la fois le soi et le non-soi : l’individu et la représentation qu’il se fait du monde. 

Comme l’écrit De Smet, "[la conscience est une construction mentale que le cerveau construit comme sas entre deux chaos : celui de nos propre neurones d'une part et celui du monde d'autre part](../documentation/observations/la%20conscience%20comme%20sas%20entre%20deux%20chaos.md)" (De Smet, 2017). Notre perception du monde serait alors produite par un dispositif artificiel - un appareillage perceptif-somatique-symbolique aussi appelé « je ». 

Ce "je" serait alors une simulation qui permettrait la transformation d'un noumène biologique en phénomène perceptible, une "*réalités pour la science, mais inaccessible à la perception sans appareillage technique*" (Vial, 2017).  Technique qui elle même structure l'expérience que nous faisons du monde puisqu'elle "[conditionne la manière dont le réel ou l'être nous apparaît](../documentation/observations/le%20monde%20est%20une%20perception%20technique.md)" (Vial, 2017). 

À la lecture de "[Aux sources de l'utopie numérique](../documentation/references/aux%20sources%20de%20l'utopie%20numérique.md)" (Turner, 2006), il est facile de constater que plusieurs mondes existent, ont existé et existeront. Souvent formés en période de guerre, d'utopie, de croyance, de peurs ou de rêves qui s'en sont suivies, ces mondes étaient pour certains des représentation collectives, et possiblement pour d'autres un peu plus individuel.

Qu'il s'agisse de techno-mysticisme, notamment au travers d'expérience interactive qui "[ressemble quelque peu à une expérience psychédélique](../documentation/observations/expérience%20interactive%20psychédélique.md)" (Turner, 2014) , d'organisme cybernétiques, web, écriture, ...


De plus, si la technique structure l'expérience que nous faisons du monde en "[conditionne(ant) la manière dont le réel ou l'être nous apparaît](../documentation/observations/le%20monde%20est%20une%20perception%20technique.md)" (Vial, 2017, p.76). 

Parler de cycle ?
Lien avec la cybernétique
Point commun entre ces mondes ?
Parles des couches ?

Dans le jeu traditionnel du Tarot, la carte du Monde symbolise l’achèvement d’un cycle, et le commencement d'un autre; le passage d'un état de convergence à un état de divergence. 
Suzane Treister, au travers de son projet HEXGEN 2.0, qui "[explore simultanément diverses réponses philosophiques, littéraires et politiques aux progrès technologiques](../documentation/references/hexgen%202.0.md)" (Treister, 2009-2011).

Conclure l'introduction sur comment on délègue de plus en plus notre "être au monde" à la machine ?

Le jeu de tarot "HEXGEN 2.0" de Suzane Treister nous a été donné comme base de réflexion pour naviguer dans les différents faits historiques et conceptuels qui ont façonné ce que nous connaissons de nos technologies numérique aujourd'hui, à commencer par le développement de la cybernétique.

Piocher une carte : le monde.

En tirant cette carte, alors que nous utilisions le jeu de tarot "HEXGEN 2.0" de Suzane Treister comme support de discussion et d'apprentissage du développement de cybernétique et de l'histoire d'internet,

Peut-être par peur du chaos qu'il représente, ne sommes-nous pas progressivement en train de déléguer notre capacité à le comprendre, l'interpréter et ainsi le fabriquer à une série d'artifice technique qui - depuis l'invention de l'écriture, semble augmenter notre potentialité de délégation à des artifices auxiliaire

Ils risquent de déléguer leurs facultés mémorielles aux supports artificiels, de réciter mécaniquement des savoirs sans en saisir le sens et de cesser d’entraîner leur propres capacités.

Ou est-il, depuis l'invention du langage et plus spécifiquement de l'écriture, un support artificiel

## Un monde "dataset"

L'émergence de la cybernétique semble être l’un des glissements majeurs du XXᵉ siècle. En  étudiant "[la manière dont les systèmes de communication pouvaient servir à des fins de contrôle](../documentation/observations/cybernétique%20et%20contrôle.md)" (Turner, 2014), Norbert Wiener définit la cybernétique comme "[un champ dédié à « l'étude des messages en tant que moyens de contrôle sur les machines et la société », les machines incluant vraisemblablement, par analogie tout au moins, les organismes biologiques](../documentation/observations/définition%20de%20la%20cybernétique.md)" (Turner, 2006, p.62). Il semblerait qu’elle ait ainsi contribué à la transformation progressive du monde en système d’information, dans lequel territoires, corps, gestes et comportements deviennent des données calculables, compréhensibles et traitables par des machines.

L’émergence de la cybernétique semble être l’un des glissements majeurs du XXᵉ siècle. En étudiant « la manière dont les systèmes de communication pouvaient servir à des fins de contrôle » (Turner, 2014, p. 62), Norbert Wiener définit la cybernétique comme « l’étude des messages en tant que moyens de contrôle sur les machines et la société », les organismes biologiques eux-mêmes étant pensés comme des systèmes d’information (ibid.). Il semblerait qu’elle ait ainsi contribué à la transformation progressive du monde en système d’information, dans lequel territoires, corps, gestes et comportements deviennent des données calculables, compréhensibles et traitables par des machines.

Cette transformation semble s’inscrire dans une quête de "singularité technologique" : la machine "comprend" désormais l’environnement, le contexte, l’objectif, et est capable d’agir seule. Une idéologie proche de celle du transhumanisme qui  "[s'appuie sur un scénario tout tracé, selon lequel l'humanité, dépassée par les performances de ses machines, sera bientôt à la merci d'une "superintelligence" prenant le contrôle de son destin](../documentation/observations/idéologie%20transhumaniste.md)" (Alombert, 2025, p.12). En somme, [une machine de toutes les machines](../documentation/observations/la%20machine%20de%20toutes%20les%20machines.md) (Simondon, 1989, p.11).

Cette datafication intensive du monde engendre des modification considérables de nos environnement, en les transformant selon des règles "primo-techniques. Des paysages entiers sont balisés, quadrillés, afin de rendre le vivant compatible avec des logiques de prédiction algorithmique. Ils deviennent des surfaces lisibles pour des capteurs et des modèles prédictifs. 

James Bridle cite par exemple le cas d’une région en Grèce, où des zones naturelles sont désormais balisées par et pour des dispositif technique, avec l'objectif d'y extraire des métaux rares : "[autant de jalons posés par une force venue d'ailleurs, résultat des opérations d'une intelligence artificielle optimisée pour extraire les ressources nécessaires afin de soutenir la sacro-sainte croissance économique, quel qu'en soit le coût.](../documentation/observations/extraction%20en%20épire.md)" (p.21).

Ainsi, le monde "dataset" se configure pour le bon fonctionnement des machines, au détriment de celui des êtres vivant qui l’habitent. Il s’instrumentalise, et transforme l’expérience "d'être au monde" en variable à ajuster, interpréter ou contrôler . Un monde pensé pour être calculé d'abord, et non plus vécu.
## Un monde "vernis"

Pour être comprise, utilisable et paraitre, d’une certaine manière, plus "naturelle", la machine - quelle que soit sa forme - se voit appliquée d’un vernis anthropomorphique. Cette couche d’humanité simulée se dissimule derrière des principes d'accessibilité, renforçant l'idée "[qu'à l'avenir, des agents d'IA capables de simuler et de répondre avec précision aux émotions humaines seront essentiels pour élargir l'adoption de l'intelligence artificielle](../documentation/observations/simuler%20les%20émotions%20humaine%20pour%20augmenter%20l'adoption.md)" (Origami, 2024).

Cette façon de penser l'interfaçage homme-machine a pour effet de réduire la complexité de nos dispositifs techniques, rendant leurs usages plus faciles. D'un autre côté, cette couche de "vernis" anthropomorphique rend difficile la lecture critique de ce qui se joue dans les usages, qu’il s’agisse de retombées écologiques, sociales, psychiques, symboliques voir même civilisationnelles.

Autrement dit, le fait que "[les machines computationnelles n'automatisent plus seulement les savoir-faire, mais aussi les savoir-penser](../documentation/observations/exploitation%20des%20ressources%20symboliques%20et%20culturelles.md)" (Alombert, 2025, p.29) ou que "[les industries numériques n'exploitent plus seulement les ressources naturelles ou matérielles mais aussi les ressources symboliques et culturelles"](../documentation/observations/exploitation%20des%20ressources%20symboliques%20et%20culturelles.md) (ibid) demeure souvent imperceptible dans nos pratiques numériques quotidiennes. 

L’émergence du Vibe Coding semble renforcer cette tendance, déplaçant le processus même de fabrication des dispositifs techniques vers le registre d’une conversation naturelle : on "parle" désormais à la machine plutôt que de la programmer. "[Communiquer remplace la nécessité de connaître le manuel](../documentation/observations/la%20communication%20remplace%20le%20manuel.md)"(Vercel, 2025) ; on ne code plus des instructions, on formule des intentions. "[L’anglais est en train de devenir le langage de programmation le plus puissant au monde - et nous assistons à cela aux premières loges](../documentation/observations/l'anglais%20comme%20langage%20de%20programmation.md)" (ibid).

Ce déplacement démocratise l’accès à un dimaine longtemps réservé à l'ingénierie logicielle, si bien qu’aujourd’hui, sans vibe coding, "[le projet ne naît pas, l’idée ne se communique pas, l’application ne sort jamais](../documentation/references/vibe%20coding%20and%20elite%20engineering.md)", explique Guillermo Rauch, CEO de Vercel. 

Derrière la transformation de ces intentions en code, se cachent une série de couches de calcul inaccessibles. C'est ce que Bratton décrit comme une "[mégastructure accidentelle](../documentation/observations/mégastructure%20accidentelle.md)" (Wikipedia, 2025), une architecture computationnelle à l’échelle planétaire opérant en dessous du seuil de perception humaine.

En retour, cette pratique produit une nouvelle forme d’opacité. Le confort dans les usages comme dans les processus de conception devient alors une forme d’anesthésie critique. John Maeda décrit ce phénomène comme une « illusion de transparence », où la simplicité de surface masque une complexité systémique inatteignable: "[les pixels d’un écran ne nous apprennent rien sur la machine computationnelle à laquelle ils sont connectés.](../documentation/observations/illusion%20de%20transparence.md)" (Maeda, 2025, p.12). 

Ce décalage entre la simplicité de l’expérience et la densité technique du système produit une perte de maîtrise cognitive : nous n’avons plus les outils pour penser les machines qui nous gouvernent. "[Au contraire, les normes techniques (…) sont dissimulées derrière des interfaces ergonomiques, qui permettent un usage immédiat et intuitif, mais rarement réflexif](../documentation/observations/usage%20ergonomique%20et%20non%20réflexif.md)" (Alombert, 2023)

Cette transparence trompeuse maintient l’illusion d’un monde sensible, alors même que l’humain semble devenir de plus en plus secondaire dans sa propre architecture technique. Non seulement nous perdons l’accès à ce qui se joue, mais nous déléguons à la machine aussi, peu à peu, nos propres facultés - au risque, peut-être, de les voir s’atrophier.
## Un monde "délégué"

Le monde que nous habitons semble désormais fabriqué - et parfois pensé - par les machines que nous avons créées. Simondon rappelait déjà que "[la machine prend la place de l’homme parce que l’homme accomplissait une fonction de machine](../documentation/observations/l'homme%20porteur%20d'outil.md)" (1958, p.15) et que, ce faisant, nous en venons à "[lui déléguer notre humanité](../documentation/observations/domination%20par%20la%20machine%20androïde.md)" (p.11). 

Si "[La machine est ce par quoi l'homme s'oppose à la mort de l'univers](../documentation/observations/la%20machine%20comme%20objet%20de%20lutte%20contre%20la%20mort.md)" (Simondon, 1958, p.15-16), n'est elle par d'abord une tentative effrénée de lutte contre notre propre mortalité ? Si "[se souvenir de la mort nous aide à mieux vivre dans cette vie](../documentation/observations/la%20mort%20nous%20rapproche%20de%20la%20vie.md)" (Bertolotti, 2023), que se passerait-il si nous devenions immortel ? Que se passera-t-il lorsque nous seront en mesure de "tout" controller ? Que nous restera-t-il ?

A moindre mesure, pendant nous travaillons à construction de "[la machine à penser, (...) la machine à vouloir, la machine à vivre](../documentation/observations/domination%20par%20la%20machine%20androïde.md)" (Simondon, 1958, p.11), se mettent en place de nouveau processus qui engendre "[non plus seulement l'automatisation des savoir-faire, mais aussi l'automatisation des savoir-penser](../documentation/observations/automatisation%20des%20savoir%20penser.md)" (Alombert, 2025, p.22).

Cette délégation traduit aussi la sacralisation de la technique : nous conférons à la machine une autorité morale, un pouvoir de décision. Nous laissons les algorithmes juger à notre place ce qu’il convient de faire ou de dire - par exemple, dans la rédaction d’un message, d’un mail, ou d'une déclaration d’amour.

Nous ne déléguons plus seulement nos calculs, mais nos choix, nos évaluations, nos jugements — et peut-être même, en un sens, nos émotions. Comme le rappelle Hubert Guillaud, "[les algorithmes sont des opinions encapsulés dans du code](../documentation/observations/les%20algorithmes%20sont%20des%20opinions%20encapsulés%20dans%20du%20code.md)" (Guillaud, 2023, p.31) : et ce sont désormais ces opinions qui orientent nos vies quotidiennes.

"[Les savoir-décider sont extériorisés dans les algorithmes de recommandation automatique, qui décident à notre place quel contenu consulter. Les savoir-traduire sont extériorisés dans les logiciels de traduction automatique, qui traduisent à notre place dans la langue exigée. Les savoir-écrire sont extéricicés dans les générateurs automatique de texte qui expriment, à notre place, nos idées.](../documentation/observations/extériorisation%20des%20savoirs.md)" (Alombert, 2025, p.23)

Ce faisant, en sollicitant un modèle de langage pour rédiger un texte, nous laissons la machine colorer nos propos, choisir l’enchaînement des mots, et nous nous privons de la part de ressenti liée à l’acte même d’écrire. Le faire-faire devient un faire-penser ou un faire-ressentir : le processus de création - et donc en un sens de ressentir - se déplace hors du corps humain.

Pourtant, la machine ne ressent pas : elle performe. L’efficacité devient son seul horizon moral. Comme le souligne Jacques Ellul, l’État moderne - tout comme la technique - est désormais régi par "[une même logique : l’efficacité, au nom d’un exercice de la rationalité](../documentation/observations/efficacité%20comme%20une%20norme.md)" (==A PRECISER==), signe que cette valeur s’impose comme norme supérieure à toute considération humaine ou morale.

Et c’est certainement dans cette efficacité que réside le potentiel destructeur de la machine. Sur le monde, comme le démontre l'expérience de pensée de la logique sans fin du Paperclip Maximizer, où une IA détruit le monde pour accomplir son objectif de fabrication de trombone ([EGO, 2024](../documentation/references/l'horreur%20existentielle%20de%20l'usine%20à%20trombones.md)). Et sur les individus, avec la "[destruction progressive des facultés de penser, par une industrie numérique qui fait des énergies psychiques sa première source de profit économique](../documentation/observations/destruction%20progressive%20des%20facultés%20de%20penser.md)" (Alombert, 2023, p.14)

Ce glissement vers une morale de l’efficacité risque donc de produire un effet miroir : nous nous algomorphisons. Nous cherchons à nous transcender, à nous optimiser, à nous augmenter. L’humain devient modèle de performance et la machine, objet d’attachement et de dépendance du savoir-être-au-monde. Comme le montre Catalog for the Post-Human, nous entrons dans une ère où "[le succès dépend de notre capacité à rester mentalement aiguisés, continuellement quantifiés, et prêts à travailler selon les horaires irréguliers dictés par des entreprises pilotées par des algorithmes](../documentation/observations/le%20succès%20dépend%20de%20notre%20augmentation.md)" (Parsons & Charlesworth, 2021). La délégation devient alors un impératif : déléguer pour tenir, déléguer pour suivre, déléguer pour rester compétitif - quitte à céder nos propres facultés.
## Un monde "résistant"

Face à cette totalisation du calcul et de la délégation, certaines pratiques semblent réintroduire la possibilité d’autres futurs. La techno-désobéissance ou les mouvements open-source rouvrent des espaces de partage, d’expérimentation et de débat. Comme le rappelait Jacques Ellul, "[l’homme est placé devant un choix exclusif : utiliser la technique comme elle doit l’être selon les règles techniques, ou ne pas l’utiliser du tout](../documentation/observations/échapper%20à%20la%20technique.md)" (==A PRECISER==).  Cette possibilité du refus demeure peut-être l’un des derniers gestes politiques face au système technicien. 

Cette éloge de la "non-puissance", qui se distingue de l'impuissance par le fait qu'elle demeure un choix : "[je peux et ne le ferai pas](../documentation/observations/eloge%20de%20la%20non-puissance.md)" (A PRECISER), invite à une réappropriation critique du monde technique, notamment par la lenteur, la friction, et la transparence. Il s'agit autrement dit - en un sens - de s'opposer à la quête de la performance et peut-être, en un sens, à accepter sa condition de "mortel", ou plus globalement d'existance finie dans un monde fini. 

Mais pour y arriver, encore faut-il avoir le choix, ou du moins, avoir conscience que l'on a le choix. Comment lutter contre l'absence du sentiment d'absence qu'engendre l'opacité de nos systèmes technique ? Est-il nécessaire de mettre en place "[un véritable contrôle démocratique des technologies](../documentation/observations/contrôle%20démocratique%20des%20technologies.md)" (Régnauld, I., & Benayoun, Y. 2024, p.179) ?

Comment redonner un pouvoir d’agir et de comprendre aux individus sans retomber dans la sur-simplification ? La théorie des capabilités d’Amartya Sen rappelle que la liberté n’est pas un état abstrait mais la possibilité concrète d’agir : La capabilité reflète la liberté de l’individu d’accéder à telle ou telle combinaison de modes de fonctionnement, autrement dit "[de choisir entre différentes conditions de vie](../documentation/observations/liberté%20de%20choix.md)" (Monnet, 2007). Autrement dit, il ne s’agit pas seulement d’offrir des options, mais de rendre réellement possibles les conditions d’un choix, d’un rapport actif au monde technique.

Le design fiction apparaît ici comme un outil de médiation intéressant : il permet de matérialiser des fragments de futurs, de les rapporter au présent et d’en faire des objets de discussion et de débat. Comme le résume Julian Bleecker, "[le design fiction est la pratique qui consiste à créer des prototypes tangibles et évocateurs issus de futurs possibles proches, afin d’explorer et de rendre visibles les conséquences des décisions que nous prenons](../documentation/observations/design%20fiction.md)" (Bleecker, n.d.). Il semble ainsi offrir un moyen pertinent pour aborder la dimension "poison" du pharmakon (==INTRODUIRE CONCEPT==) technique, sans exiger de maîtriser l’ensemble de ses mécanismes internes.

Ce faisant, les prototypes diégétiques donnent forme a des logiques a-priori invisibles, offrant une intelligibilité sensible à ce qui échappe au regard du quotidien. Ces approches et usages de la technologies s’opposent en un sens au solutionnisme technologique, en réintroduisant la pluralité des possibles et en réouvrant le débat public sur le devenir technologique. Ils rappellent ainsi que "[les technologies ne sont pas d'emblée des solutions: elles doivent faire l'objet d'interprétations, de réflexions, de délibérations et de décisions - elles doivent être adoptées socialement et politiquement](../documentation/observations/la%20technique%20n'est%20pas%20neutre.md)" (Alombert, 2025, p.42).

C'est peut-être ce qu'invite Jacque Ellul à faire lorsqu'il rappelle qu'on "[ne peut pas luter contre l’efficacité avec efficacité. On doit utiliser des choses qui ne sont pas efficaces, qui prennent leur temps](../documentation/observations/luter%20contre%20la%20technique.md)" (Devaux et cie., 2025). Il s'oppose en somme à l'idée de combattre la démesure technique par une surenchère technologique, là ou "[l’augmentation devient destruction et le remède poison](../documentation/observations/la%20mémoire%20artificielle%20rend%20l’oubli%20habituel.md)" (Alombert, 2023, p.43). Le design fiction, au contraire, propose de réintroduire le symbolique, le récit et la réflexivité comme antidotes à "[l’automatisation de la pensée](../documentation/observations/automatisation%20de%20la%20pensée.md)" (ibid, p.44).

On peut y lire une issue - fragile, mais possible. Si tout est délégué aux machines, il restera peut-être à l’humain la question du sens : qu’est-ce qu’être vivant, qu’est-ce que l'amour, qu’est-ce qu’éprouver ? Qu'est-ce qu'être humain ? L’automatisation totale pourrait paradoxalement nous ramener à ces interrogations fondamentales, et forcer un retour à l’émotion, au doute, à la réflexivité... pour autant que nous soyons encore capable de penser. 

[A REFORMULER]Les mondes synthétique n’est donc pas une fin : il est une condition. Une condition à partir de laquelle il nous appartient de réapprendre à sentir dans un monde qui simule le vivant - à retrouver du sens dans l'absence d’efficacité, de la lenteur dans la vitesse, et de la présence dans la simulation.

---
# The Synthetic Worlds 

## Description

- Talk about the extractivist (and not generative) logic of AI.
- Talk about how we transform the world to make it readable by machines.
- It uses the first words a human typically exchanges when creating a robot (Hello, World!) as an ASCII characters to represent the world.
- It represents the end or completion of a cycle, in this case, the cycle of the digitalization of the world.
- The two slashes add put "synthetic" as comment, and evoke the two wands held by the woman on the original card.
- The grid represents the standardization of the world, of ways of thinking, of know-how, of knowledge...
- The title typography is that of the Whole Earth Catalog.
- ASCII characters also refer to the concept of artificial memory (or more broadly, artificialized know-how).

## Print

- Could be printed with an axidraw robot.

## Preview

![The Synthetic Worlds](assets/the%20synthetic%20worlds.png)
