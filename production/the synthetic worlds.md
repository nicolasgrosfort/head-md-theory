# The Synthetic Worlds

## Introduction

Le monde que nous habitons n'a peut-être jamais existé en tant que "donnée" brute, mais toujours et plutôt en tant que construction (==Symbole, représentation==). Ils est fabriqués par des techniques, des récits, des représentations qui filtrent et reconfigurent nos perceptions. Comme le rappelle Stéphane Vial, "[la technique conditionne la manière dont le réel ou l’être nous apparaît](../documentation/observations/le%20monde%20est%20une%20perception%20technique.md)" (Vial, 2017, p76) : elle agit comme un appareillage perceptif qui compose notre rapport au monde. Ce réel est donc un ensemble "[multiples (de) couches interconnectées](../documentation/observations/les%20multiples%20couches%20interconnectées%20dont%20dépend%20le%20calcul%20à%20l'échelle%20planétaire.md)" (Wikipedia, 2025), somatiques, symboliques et techniques, qui participe à la fabrication - et parfois peut-être à la destruction - de "[l'habitabilité du monde](../documentation/observations/habitabilité%20du%20monde.md)" (Gauthier & cie, 2014). (==LIEN AVEC LE COOURS DE ANDRE==), avec le fait que la machine fixe dans le temps une réalité organique qui évolue... quelque chose comme ça ? 

Ces multiples couches produise ce que je m'essaie à nommer "les mondes synthétiques". Des mondes modelés par la logique du calcul, par la prédiction, par l’anthropomorphisation des machines et par la délégation progressives de nos facultés d'être-au-monde. Monde *dataset*, monde *vernis*, monde *délégué* et monde *résistant* : ces mondes coexistent, se superposent, parfois s’affrontent. Ensemble, ils dessinent une mutation profonde de notre rapport au réel et reconfigure silencieusement la place - et surtout le role - que nous y tenons.  (avec des questionnement qui ne datent peut-être pas d'aujourd'hui, lien cybernétique ?)
## Un monde *dataset*

L'émergence de la cybernétique semble être l’un des glissements majeurs du XXᵉ siècle. En  étudiant "[la manière dont les systèmes de communication pouvaient servir à des fins de contrôle](../documentation/observations/cybernétique%20et%20contrôle.md)" (Turner, 2014), Norbert Wiener définit la cybernétique comme "[un champ dédié à « l'étude des messages en tant que moyens de contrôle sur les machines et la société », les machines incluant vraisemblablement, par analogie tout au moins, les organismes biologiques](../documentation/observations/définition%20de%20la%20cybernétique.md)" (Turner, 2006, p.62). 
Elle semble ainsi avoir participé à l’émergence d’une nouvelle manière de concevoir le monde - comme un système d’information - dans lequel territoires, corps, gestes et comportements deviennent progressivement des données calculables, analysables et traitables par des machines.

Cette transformation semble s’inscrire dans une quête de "singularité technologique" : une machine capable de comprendre l’environnement, d’anticiper le contexte, de saisir un objectif et d’agir de manière autonome. Une idéologie qui n’est pas sans rappeler celle du transhumanisme, lequel "[s'appuie sur un scénario tout tracé, selon lequel l'humanité, dépassée par les performances de ses machines, sera bientôt à la merci d'une "superintelligence" prenant le contrôle de son destin](../documentation/observations/idéologie%20transhumaniste.md)" (Alombert, 2025, p.12). En somme, pour reprendre Simondon, la promesse d’une "[machine de toutes les machines](../documentation/observations/la%20machine%20de%20toutes%20les%20machines.md)" (1989, p.11).

Cette datafication intensive du monde engendre des transformations considérables de nos environnements, en les remodelant selon des logiques primo-techniques. Des paysages entiers sont balisés, quadrillés, mesurés, afin de rendre le vivant compatible avec des logiques de prédiction algorithmique. Ils deviennent des surfaces lisibles : des environnements optimisés pour des capteurs, des flux de données et des modèles prédictifs.

James Bridle cite par exemple le cas d’une région en Épire (Grèce), où des zones naturelles sont désormais balisées par - et pour - des dispositifs techniques, afin d’y extraire des métaux rares. Il décrit ces installations comme "[autant de jalons posés par une force venue d'ailleurs, résultat des opérations d'une intelligence artificielle optimisée pour extraire les ressources nécessaires afin de soutenir la sacro-sainte croissance économique, quel qu'en soit le coût](../documentation/observations/extraction%20en%20épire.md)" (p.21).

Ainsi, le monde *dataset* se configure pour le bon fonctionnement des machines, au détriment des êtres vivants qui l’habitent. Il s’instrumentalise et transforme l’expérience d’"être-au-monde" en une variable à ajuster, interpréter ou contrôler.
Un monde qui se laisse calculer plus facilement qu’il ne se laisse habiter,
## Un monde *vernis*

Pour être comprise, utilisable et paraître, d’une certaine manière, plus "naturelle", la machine - quelle que soit sa forme - se voit recouverte d’un vernis anthropomorphique. Cette couche d’humanité simulée sert d’interface apaisante, une médiation émotionnelle qui se dissimule derrière des principes d’accessibilité et d’usage intuitif. Elle renforce l'idée "[qu'à l'avenir, des agents d'IA capables de simuler et de répondre avec précision aux émotions humaines seront essentiels pour élargir l'adoption de l'intelligence artificielle](../documentation/observations/simuler%20les%20émotions%20humaine%20pour%20augmenter%20l'adoption.md)" (Origami, 2024).

Cette manière de penser l’interfaçage homme-machine réduit la complexité apparente de nos dispositifs techniques, en rendant leur usage plus accessible et plus immédiat. Mais, en parallèle, cette couche de vernis anthropomorphique rend plus difficile une lecture critique de ce qui s’y joue : qu’il s’agisse des retombées écologiques, sociales, psychiques, symboliques ou même civilisationnelles.

Autrement dit, le fait que "[les machines computationnelles n'automatisent plus seulement les savoir-faire, mais aussi les savoir-penser](../documentation/observations/exploitation%20des%20ressources%20symboliques%20et%20culturelles.md)" (Alombert, 2025, p.29) ou que "[les industries numériques n'exploitent plus seulement les ressources naturelles ou matérielles mais aussi les ressources symboliques et culturelles"](../documentation/observations/exploitation%20des%20ressources%20symboliques%20et%20culturelles.md) (ibid), demeure largement imperceptible dans nos pratiques numériques quotidiennes. 

L’émergence du Vibe Coding semble renforcer cette tendance, en déplaçant le processus même de fabrication des dispositifs techniques vers le registre d’une conversation "naturelle" : on *parle* désormais à la machine plutôt que de la programmer. "[Communiquer remplace la nécessité de connaître le manuel](../documentation/observations/la%20communication%20remplace%20le%20manuel.md)"(Vercel, 2025) ; on ne code plus des instructions, on formule des intentions. "[L’anglais est en train de devenir le langage de programmation le plus puissant au monde - et nous assistons à cela aux premières loges](../documentation/observations/l'anglais%20comme%20langage%20de%20programmation.md)" (ibid).

Ce déplacement démocratise l’accès à un domaine longtemps réservé à l’ingénierie logicielle. Si bien qu’aujourd’hui, sans _vibe coding_, "[le projet ne naît pas, l’idée ne se communique pas, l’application ne sort jamais](../documentation/references/vibe%20coding%20and%20elite%20engineering.md)", explique Guillermo Rauch, CEO de Vercel. 

Mais derrière cette apparente simplicité - transformer des intentions en code - se déploie une série de couches de calcul inaccessibles. C'est ce que Bratton décrit comme une "[mégastructure accidentelle](../documentation/observations/mégastructure%20accidentelle.md)" (Wikipedia, 2025) : une architecture computationnelle à l’échelle planétaire, opérant en dessous du seuil de perception humaine.

En retour, cette pratique produit une nouvelle forme d’opacité. Le confort, tant dans les usages que dans les processus de conception, devient une véritable anesthésie critique. John Maeda décrit ce phénomène comme une *illusion de transparence*, où la simplicité de surface masque une complexité systémique inatteignable: "[les pixels d’un écran ne nous apprennent rien sur la machine computationnelle à laquelle ils sont connectés.](../documentation/observations/illusion%20de%20transparence.md)" (Maeda, 2025, p.12). 

Ce décalage entre la simplicité de l’expérience et la densité technique du système entraîne une perte de maîtrise cognitive : nous n’avons plus les outils pour penser les machines qui nous gouvernent. Comme le rappelle Alombert, "[les normes techniques (…) sont dissimulées derrière des interfaces ergonomiques, qui permettent un usage immédiat et intuitif, mais rarement réflexif](../documentation/observations/usage%20ergonomique%20et%20non%20réflexif.md)" (2023)

Cette transparence trompeuse maintient l’illusion d’un monde sensible, alors même que l’humain devient de plus en plus secondaire dans sa propre architecture technique. Non seulement nous perdons l’accès à ce qui s’y joue, mais nous déléguons également à la machine, peu à peu, nos propres facultés - au risque, peut-être, de les voir s’atrophier.
## Un monde *délégué*

Le monde que nous habitons semble désormais fabriqué - et parfois même pensé - par les machines que nous avons créées. Simondon rappelait déjà que "[la machine prend la place de l’homme parce que l’homme accomplissait une fonction de machine](../documentation/observations/l'homme%20porteur%20d'outil.md)" (1958, p.15) et que, ce faisant, nous en venons à "[lui déléguer notre humanité](../documentation/observations/domination%20par%20la%20machine%20androïde.md)" (ibid, p.11). 

Si "[La machine est ce par quoi l'homme s'oppose à la mort de l'univers](../documentation/observations/la%20machine%20comme%20objet%20de%20lutte%20contre%20la%20mort.md)" (Simondon, 1958, p.15-16), n’est-elle pas d’abord une tentative effrénée de lutter contre notre propre mortalité ? Et si, comme l’écrit Bertolotti, "[se souvenir de la mort nous aide à mieux vivre dans cette vie](../documentation/observations/la%20mort%20nous%20rapproche%20de%20la%20vie.md)" (2023), que deviendrions-nous si nous devenions immortels ? Que se passera-t-il lorsque nous serons en mesure de "tout" contrôler ? Que nous restera-t-il alors ?

À une moindre échelle, pendant que nous travaillons à la construction de "[la machine à penser, (...) la machine à vouloir, la machine à vivre](../documentation/observations/domination%20par%20la%20machine%20androïde.md)" (Simondon, 1958, p.11), se mettent en place de nouveaux processus qui engendre "[non plus seulement l'automatisation des savoir-faire, mais aussi l'automatisation des savoir-penser](../documentation/observations/automatisation%20des%20savoir%20penser.md)" (Alombert, 2025, p.22).

Cette délégation traduit aussi une forme de sacralisation de la technique : nous conférons à la machine une autorité morale, un pouvoir de décision. Nous laissons les algorithmes juger à notre place ce qu’il convient d’écrire, de dire ou même ce qu’il convient de ressentir - qu’il s’agisse de rédiger un message, un e-mail, ou parfois même une déclaration d’amour.

Nous ne déléguons plus seulement nos calculs, mais aussi nos choix, nos évaluations, nos jugements - et peut-être même, en un sens, nos émotions. Comme le rappelle Hubert Guillaud, "[les algorithmes sont des opinions encapsulés dans du code](../documentation/observations/les%20algorithmes%20sont%20des%20opinions%20encapsulés%20dans%20du%20code.md)" (Guillaud, 2023, p.31). Or ce sont désormais ces opinions - celles de leurs concepteurs - qui orientent silencieusement nos décisions quotidiennes.

Cette délégation ne concerne plus uniquement des tâches mécaniques ou computationnelles : elle emporte avec elle des pans entiers de nos facultés cognitives. Comme le formule Alombert, "[les savoir-décider sont extériorisés dans les algorithmes de recommandation automatique, qui décident à notre place quel contenu consulter. Les savoir-traduire sont extériorisés dans les logiciels de traduction automatique, qui traduisent à notre place dans la langue exigée. Les savoir-écrire sont extéricicés dans les générateurs automatique de texte qui expriment, à notre place, nos idées.](../documentation/observations/extériorisation%20des%20savoirs.md)" (Alombert, 2025, p.23). Autrement dit, ce ne sont plus seulement nos gestes qui sont délégués, mais nos capacités mêmes à formuler, interpréter, choisir.

Ce faisant, en sollicitant un modèle de langage pour rédiger un texte, nous laissons la machine colorer nos propos, ajuster le ton, choisir l’enchaînement des mots, structurer la logique interne d’un raisonnement. Nous nous privons alors d’une part essentielle de l’expérience d’écriture : la construction progressive de la pensée. Le _faire-faire_ devient un _faire-penser_ - voire un _faire-ressentir_ : le processus même de création, et donc une part du vécu qu’il mobilise, se déplace hors du corps humain.

Pourtant, la machine - elle - ne ressent pas : elle exécute. Elle ne connaît ni hésitation, ni ambivalence, ni friction intérieure ; elle performe. L’efficacité devient alors son seul horizon moral. Comme le souligne Jacques Ellul, l’État moderne - tout comme la technique - est régi par "[une même logique : l’efficacité, au nom d’un exercice de la rationalité](../documentation/observations/efficacité%20comme%20une%20norme.md)" (Larmagnac-Matheron, 2024). Ce glissement marque l’installation d’une norme qui tend à s’imposer au-dessus de toute considération humaine, politique ou morale.

Et c’est certainement dans cette efficacité que réside le potentiel destructeur de la machine. 

Destructeur pour le monde, comme le montre l’expérience de pensée du _Paperclip Maximizer_, dans laquelle une IA pousse jusqu’à l'absurde la logique d’optimisation : détruire toute matière disponible pour atteindre son objectif unique - produire toujours plus de trombones ([EGO, 2024](../documentation/references/l'horreur%20existentielle%20de%20l'usine%20à%20trombones.md)). 

Destructeur aussi pour les individus, lorsque cette même logique d’efficacité s’applique à l’esprit humain : elle entraîne une "[destruction progressive des facultés de penser, par une industrie numérique qui fait des énergies psychiques sa première source de profit économique](../documentation/observations/destruction%20progressive%20des%20facultés%20de%20penser.md)" (Alombert, 2023, p.14)

Ce glissement vers une morale de l’efficacité risque alors de produire un effet miroir : nous nous *algomorphisons*. Nous cherchons à nous transcender, à nous optimiser, à nous augmenter. L’humain devient modèle de performance ; la machine, elle, devient un objet d’attachement, de projection, parfois même de dépendance dans notre manière d’être-au-monde. Comme le montre _Catalog for the Post-Human_, nous entrons dans une ère où "[le succès dépend de notre capacité à rester mentalement aiguisés, continuellement quantifiés, et prêts à travailler selon les horaires irréguliers dictés par des entreprises pilotées par des algorithmes](../documentation/observations/le%20succès%20dépend%20de%20notre%20augmentation.md)" (Parsons & Charlesworth, 2021). 

Dans un tel contexte, la délégation n’est plus un choix, mais un impératif : déléguer pour tenir, déléguer pour rester compétitif, déléguer pour survivre - quitte à en perdre progressivement nos propres facultés.
## Un monde *résistant*

Face à cette totalisation du calcul et de la délégation, certaines pratiques réintroduisent la possibilité d’autres futurs. La techno-désobéissance, les mouvements open-source, les tactiques de détournement ou de réappropriation technique rouvrent des espaces de partage, d’expérimentation et de débat. Elles rappellent que la technique n’est pas un destin, mais un terrain de lutte. Comme le soulignait Jacques Ellul, "[l’homme est placé devant un choix exclusif : utiliser la technique comme elle doit l’être selon les règles techniques, ou ne pas l’utiliser du tout](../documentation/observations/échapper%20à%20la%20technique.md)" (Larmagnac-Matheron, 2024). Dans cette perspective, la simple possibilité du refus - ou du détournement - demeure peut-être l’un des derniers gestes politiques face au système technicien.

Cette éloge de la _non-puissance_, qui se distingue de l’impuissance parce qu’elle demeure un choix - "[je peux et ne le ferai pas](../documentation/observations/eloge%20de%20la%20non-puissance.md)" (Larmagnac-Matheron, 2024) - invite à réinvestir le monde technique autrement, par la lenteur, la friction, et la transparence. Il s’agit, en un sens, de s’opposer à la quête de performance qui gouverne nos dispositifs, et peut-être d’accepter notre condition de mortels - ou, plus largement, d’êtres finis dans un monde fini.

Mais pour y parvenir, encore faut-il avoir le choix - ou, du moins, avoir conscience qu’un choix existe. Comment lutter contre _l’absence du sentiment d’absence_ qu’engendre l’opacité de nos systèmes techniques ? Faut-il, pour cela, instaurer "[un véritable contrôle démocratique des technologies](../documentation/observations/contrôle%20démocratique%20des%20technologies.md)" (Régnauld, I., & Benayoun, Y. 2024, p.179), afin de rendre à chacun la possibilité de comprendre, d’interroger et, éventuellement, de refuser ce qui lui est imposé ?

Comment redonner un pouvoir d’agir et de comprendre aux individus, sans retomber dans la sur-simplification ? La théorie des capabilités d’Amartya Sen rappelle que la liberté n’est pas un état abstrait, mais une puissance concrète d’agir. La capabilité désigne ainsi la liberté effective d’accéder à telle ou telle combinaison de modes de fonctionnement, autrement dit "[de choisir entre différentes conditions de vie](../documentation/observations/liberté%20de%20choix.md)" (Monnet, 2007). Autrement dit, il ne s’agit pas seulement d’offrir des options, mais de rendre réellement possibles les conditions d’un choix - les conditions d’un rapport actif, situant et situé, au monde technique.

Le design fiction apparaît ici comme un outil de médiation intéressant : il permet de matérialiser des fragments de futurs, de les rapporter au présent et d’en faire des objets de discussion et de débat. Comme le résume Julian Bleecker, "[le design fiction est la pratique qui consiste à créer des prototypes tangibles et évocateurs issus de futurs possibles proches, afin d’explorer et de rendre visibles les conséquences des décisions que nous prenons](../documentation/observations/design%20fiction.md)" (Bleecker, n.d.). Il semble ainsi offrir un moyen pertinent pour aborder la dimension _poison_ du pharmakon technique - ce terme grec qui, chez Platon, "[a une double signification: à la fois celle du remède et celle du poison](../documentation/observations/pharmakon.md)" (Alombert, 2025) - sans pour autant exiger la maîtrise de ses mécanismes internes.

Ce faisant, les prototypes diégétiques donnent forme à des logiques a priori invisibles, offrant une intelligibilité sensible à ce qui échappe au regard du quotidien. Ces approches et usages de la technologie s’opposent, en un sens, au solutionnisme technologique, en réintroduisant la pluralité des possibles et en réouvrant le débat public sur le devenir technique. Ils rappellent ainsi que "[les technologies ne sont pas d'emblée des solutions: elles doivent faire l'objet d'interprétations, de réflexions, de délibérations et de décisions - elles doivent être adoptées socialement et politiquement](../documentation/observations/la%20technique%20n'est%20pas%20neutre.md)" (Alombert, 2025, p.42).

C’est peut-être à cela que nous invite Jacques Ellul lorsqu’il rappelle qu’on "[ne peut pas luter contre l’efficacité avec efficacité. On doit utiliser des choses qui ne sont pas efficaces, qui prennent leur temps](../documentation/observations/luter%20contre%20la%20technique.md)" (Devaux et cie., 2025). l s’oppose ainsi à l’idée de combattre la démesure technique par une surenchère technologique - là où "[l’augmentation devient destruction et le remède poison](../documentation/observations/la%20mémoire%20artificielle%20rend%20l’oubli%20habituel.md)" (Alombert, 2023, p.43).  Le design fiction, au contraire, propose de réintroduire le symbolique, le récit et la réflexivité comme antidotes à "[l’automatisation de la pensée](../documentation/observations/automatisation%20de%20la%20pensée.md)" (ibid, p.44).

On peut y lire une issue - fragile, mais possible. Si tout est délégué aux machines, il restera peut-être à l’humain ce qui ne peut être automatisé : la question du sens. Qu’est-ce qu’être vivant ? Qu’est-ce qu’aimer ? Qu’est-ce qu’éprouver ? Qu’est-ce qu’être humain ? L’automatisation totale pourrait, paradoxalement, nous ramener à ces interrogations fondamentales et forcer un retour à l’émotion, au doute, à la réflexivité… pour autant que nous soyons encore capables de penser.

C’est peut-être aussi ce qu’annonçait, avec une naïveté désarmante, le poème de Richard Brautigan :

> [Sous la haute surveillance de machines pleines d'amour et de grâce](../documentation/observations/sous%20la%20haute%20surveillance%20de%20machines%20pleines%20d'amour%20et%20de%20grâce.md) 
> 
> *Il me plaît à imaginer (et le plus tôt le mieux!) une prairie cybernétique ou mammifères et ordinateurs vivent ensemble une harmonie mutuellement programmée semblable à de l'eau pure effleurant un ciel sans nuage.*
> 
> *Il me plaît à imaginer (tout de suite, allons!) une forêt cybernétique semée d'électronique et de pins où les cerfs flânent en paix au-dessus d'ordinateurs pareils à des fleurs aux pétales filés.*
> 
> *Il me plaît à imaginer (il en sera ainsi!) une écologie cybernétique où nous sommes libres de tout travail réunis à la nature, mêlés aux mammifères nos frères et sœurs et sous la haute surveillance de machines pleines d'amour et de grâce.*

(Turner, 2006, p.94)

Les mondes synthétiques semblent ainsi réaliser le "vieux" rêve cybernétique : celui d’une réalité entièrement convertie en information. Mais il reste à savoir si, dans ce paysage quadrillé par le calcul, nous pourrons encore entendre autre chose que le silence des machines - un geste, un doute, un soupir. 

C’est peut-être là que se joue notre avenir : dans la part de vivant qui échappe encore aux modèles.(==RE TRAVAILLER==) 
# The Card 

![The Synthetic Worlds](assets/the%20synthetic%20worlds.png)

## Intentions

- Met en scène la logique extractiviste de l’IA, qui puise dans les productions humaines plutôt qu’elle ne "génère" véritablement, et rappelle les coûts invisibles de cette extraction.
- Montre comment nous remodelons progressivement le monde pour l’adapter aux attentes des machines, afin qu’il devienne entièrement découpable, mesurable, indexable.
- Recompose la planète à partir de “Hello, World!”, ces premiers mots prononcés par un humain face à une machine : une manière de signifier que le monde lui-même devient un message adressé aux systèmes computationnels.
- Représente la fin ou l’aboutissement d’un cycle : celui de la numérisation du monde.
- Les doubles barres “//” inscrivent “synthetic” comme un commentaire de code, et rappellent subtilement les deux bâtons de la figure féminine de la carte originelle.
- La grille évoque l’uniformisation des formes de vie et de pensée sous l’effet du calcul, la rationalisation des savoir-faire, et la mise à plat des singularités culturelles.
- Le choix typographique renvoie au [Whole Earth Catalog](../documentation/references/whole%20earth%20catalog.md), symbole d’un imaginaire technologique à la fois utopique et pré-internet.
- L’usage de l’ASCII renvoie à l’histoire des mémoires artificielles, et plus largement à la traduction du monde en signes manipulables par les ordinateurs.
- L’ASCII évoque aussi la pauvreté expressive des systèmes techniques, - réduisant la complexité du monde à des symboles élémentaires (ici "hello world")
- La composition “monde + grille” rappelle les fantasmagories cybernétiques des années 1960-70, notamment les environnements immersifs du Pepsi Pavilion ou les visions “globales” de Fuller et du Whole Earth Catalog.
- Le vide autour du globe suggère la disparition du vivant dans un espace totalement calculé.
- Fait echos à la [première image de la terre depuis l'espace](../documentation/references/première%20image%20de%20la%20terre%20depuis%20l'espace.md), aussi utilisée dans le [Whole Earth Catalog](../documentation/references/whole%20earth%20catalog.md).
## Processus

- Sera imprimée avec un Robot Axidraw
# Présentation [en]

...
# À placer dans mon texte ? 

[exploitation des ressources symboliques et culturelles](../documentation/observations/exploitation%20des%20ressources%20symboliques%20et%20culturelles.md)

Comme l’écrit De Smet, "[la conscience est une construction mentale que le cerveau construit comme sas entre deux chaos : celui de nos propre neurones d'une part et celui du monde d'autre part](../documentation/observations/la%20conscience%20comme%20sas%20entre%20deux%20chaos.md)" (De Smet, 2017). Notre perception du monde serait alors produite par un dispositif artificiel - un appareillage perceptif-somatique-symbolique aussi appelé « je ». 

Qu'il s'agisse de techno-mysticisme, notamment au travers d'expérience interactive qui "[ressemble quelque peu à une expérience psychédélique](../documentation/observations/expérience%20interactive%20psychédélique.md)" (Turner, 2014) , d'organisme cybernétiques, web, écriture, ...

Dans le jeu traditionnel du Tarot, la carte du Monde symbolise l’achèvement d’un cycle, et le commencement d'un autre; le passage d'un état de convergence à un état de divergence. 
Suzane Treister, au travers de son projet HEXGEN 2.0, qui "[explore simultanément diverses réponses philosophiques, littéraires et politiques aux progrès technologiques](../documentation/references/hexgen%202.0.md)" (Treister, 2009-2011).

Peut-être par peur du chaos qu'il représente, ne sommes-nous pas progressivement en train de déléguer notre capacité à le comprendre, l'interpréter et ainsi le fabriquer à une série d'artifice technique qui - depuis l'invention de l'écriture, semble augmenter notre potentialité de délégation à des artifices auxiliaire